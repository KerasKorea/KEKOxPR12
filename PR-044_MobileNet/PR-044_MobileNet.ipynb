{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PR-044 MobileNet\n",
    "\n",
    "이진원 님의 [MobileNet 강의](https://www.youtube.com/watch?v=7UoOFKcyIvM&index=45&list=PLlMkM4tgfjnJhhd4wn5aj8fVTYJwIpWkS) 감사드립니다.\n",
    "\n",
    "MobileNet을 통해 cifar10 데이터를 학습시켜 보겠습니다.\n",
    "\n",
    "논문: https://arxiv.org/abs/1704.04861"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "\n",
    "<code> pip install opencv-python</code>\n",
    "\n",
    "<code> pip install scikit-learn</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set\n",
    "케라스에서는 손쉽게 CIFAR-10 데이터를 쓸 수 있도록 api를 제공해 줍니다.\n",
    "\n",
    "또한 [data generator](https://keras.io/preprocessing/image/)를 이용하여 augmentation을 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# normalization\n",
    "x_train = np.array(x_train) / 127.5 - 1\n",
    "x_test = np.array(x_test) / 127.5 - 1\n",
    "\n",
    "# one-hot encoding\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# train data의 1/4을 validation set으로 활용합니다.\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "모바일 넷 전체 구조입니다.\n",
    "\n",
    "![image.png](mobilenet.png)\n",
    "\n",
    "위 전체 구조에서의 conv, dw_conv 는 아래와 같은 형태입니다.\n",
    "![image.png](set.png)\n",
    "\n",
    "가장 먼저 depthwise convolution 을 만들어야 합니다.\n",
    "\n",
    "케라스에서 사용 가능한 seperable conv2d 는 depthwise convolution 이후 pointwise convolution 까지 수행해 주는\n",
    "\n",
    "일종의 xception 용 통합 솔루션 입니다.\n",
    "\n",
    "모바일 넷에서는 depthwise conv 와 pointwise conv 사이에 batch norm, activation이 들어가는데\n",
    "\n",
    "이를 위해 새로운 custom layer를 작성하겠습니다.\n",
    "\n",
    "backend에서 제공하는 depthwise conv를 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layer 의 대부분은 boilerplate 입니다.\n",
    "# 미리 맞춰진 틀에 구현할 내용은 얼마 없습니다.\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "\n",
    "# layer는 4-shape (batch, h, w, ch) 형태를 받습니다.\n",
    "class DepthwiseConv2D(Layer):\n",
    "    # hyperparameter들을 인자로 받습니다.\n",
    "    def __init__(self, k_size, strides, padding, depth_multiplier, kernel_regularizer=None, **kwargs):\n",
    "        self.k_size = k_size\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.regularizer = kernel_regularizer\n",
    "        \n",
    "        super(DepthwiseConv2D, self).__init__(**kwargs)\n",
    "\n",
    "    # build 함수에서는 학습 시킬 수 있는 weight를 정의합니다.\n",
    "    def build(self, input_shape):\n",
    "        self.depthwise_kernel = self.add_weight(\n",
    "            name='depthwise_kernel',\n",
    "            shape=(self.k_size[0],\n",
    "                   self.k_size[1],\n",
    "                   int(input_shape[3]),\n",
    "                   self.depth_multiplier),\n",
    "            initializer='glorot_normal',\n",
    "            regularizer=self.regularizer,\n",
    "            trainable=True)\n",
    "        \n",
    "        super(DepthwiseConv2D, self).build(input_shape)\n",
    "\n",
    "    # call 함수에는 실질적으로 output을 계산해내는 과정을 담습니다.\n",
    "    def call(self, x):\n",
    "        return K.depthwise_conv2d(x, self.depthwise_kernel,\n",
    "                                  strides=self.strides,\n",
    "                                  padding=self.padding,\n",
    "                                  dilation_rate=(1, 1),\n",
    "                                  data_format=\"channels_last\")\n",
    "                    \n",
    "    # 마지막 이 함수에는 output의 크기를 정의해 줍니다. \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        rows = conv_output_length(input_shape[1], \n",
    "                                  self.k_size[0],\n",
    "                                  self.padding,\n",
    "                                  self.strides[0])\n",
    "        \n",
    "        cols = conv_output_length(input_shape[2], \n",
    "                                  self.k_size[1],\n",
    "                                  self.padding,\n",
    "                                  self.strides[1])\n",
    "        \n",
    "        out_filters = input_shape[3] * self.depth_multiplier\n",
    "\n",
    "        return (input_shape[0], rows, cols, out_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, Activation, Reshape, Input, Dropout\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras import regularizers\n",
    "\n",
    "def conv_layer_init(x, filters, stride):\n",
    "    x = Conv2D(filters, (3, 3),\n",
    "               strides=(stride, stride),\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# 1x1 conv_layer 세트\n",
    "def conv_layer_1x1(x, filters):\n",
    "    x = Conv2D(filters, (1, 1),\n",
    "               strides=(1, 1),\n",
    "               padding='same',\n",
    "               use_bias=False,\n",
    "               kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# 3x3 depthwise_conv_layer 세트\n",
    "def conv_layer_dw(x, stride):\n",
    "    x = DepthwiseConv2D((3, 3),\n",
    "                        strides=(stride, stride),\n",
    "                        depth_multiplier=1,\n",
    "                        padding='same',\n",
    "                        kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(32, 32, 3))\n",
    "\n",
    "x = conv_layer_init(input_img, 32, 2)\n",
    "x = conv_layer_dw(x, 1)\n",
    "\n",
    "x = conv_layer_1x1(x, 64)\n",
    "x = conv_layer_dw(x, 2)\n",
    "\n",
    "x = conv_layer_1x1(x, 128)\n",
    "x = conv_layer_dw(x, 1)\n",
    "x = conv_layer_1x1(x, 128)\n",
    "x = conv_layer_dw(x, 2)\n",
    "\n",
    "x = conv_layer_1x1(x, 256)\n",
    "x = conv_layer_dw(x, 1)\n",
    "x = conv_layer_1x1(x, 256)\n",
    "x = conv_layer_dw(x, 2)\n",
    "\n",
    "for i in range(5):\n",
    "    x = conv_layer_1x1(x, 512)\n",
    "    x = conv_layer_dw(x, 1)\n",
    "x = conv_layer_1x1(x, 512)\n",
    "x = conv_layer_dw(x, 2)\n",
    "\n",
    "x = conv_layer_1x1(x, 1024)\n",
    "x = conv_layer_dw(x, 1)\n",
    "x = conv_layer_1x1(x, 1024)\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Reshape((1, 1, 1024))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(10, (1, 1), padding='same')(x)\n",
    "x = Activation('softmax')(x)\n",
    "x = Reshape((10,))(x)\n",
    "\n",
    "model = Model(input_img, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "import math\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return max(1e-4, 1e-3 * math.pow(0.7, epoch // 5))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint = ModelCheckpoint(filepath='model_{epoch:02d}.h5', \n",
    "                             save_best_only=True, \n",
    "                             save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 28.0865 - acc: 0.2085 - val_loss: 13.0324 - val_acc: 0.2861\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 8.3813 - acc: 0.3004 - val_loss: 5.4965 - val_acc: 0.3082\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 4.3881 - acc: 0.3302 - val_loss: 3.6756 - val_acc: 0.3201\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 3.0486 - acc: 0.3632 - val_loss: 2.6188 - val_acc: 0.3808\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 2.3394 - acc: 0.4176 - val_loss: 2.1059 - val_acc: 0.4504\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.9424 - acc: 0.4831 - val_loss: 1.9442 - val_acc: 0.4588\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.7870 - acc: 0.5167 - val_loss: 1.7398 - val_acc: 0.5318\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.6618 - acc: 0.5438 - val_loss: 1.7801 - val_acc: 0.5025\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.5886 - acc: 0.5656 - val_loss: 1.6282 - val_acc: 0.5454\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.5203 - acc: 0.5855 - val_loss: 1.5604 - val_acc: 0.5722\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.4099 - acc: 0.6176 - val_loss: 1.4845 - val_acc: 0.5877\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3545 - acc: 0.6290 - val_loss: 1.3795 - val_acc: 0.6155\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3260 - acc: 0.6378 - val_loss: 1.3831 - val_acc: 0.6185\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.2936 - acc: 0.6483 - val_loss: 1.2572 - val_acc: 0.6545\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2648 - acc: 0.6562 - val_loss: 1.3079 - val_acc: 0.6509\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2069 - acc: 0.6736 - val_loss: 1.1876 - val_acc: 0.6758\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1604 - acc: 0.6891 - val_loss: 1.1162 - val_acc: 0.6969\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1405 - acc: 0.6953 - val_loss: 1.1420 - val_acc: 0.6844\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1237 - acc: 0.6947 - val_loss: 1.1426 - val_acc: 0.6843\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1118 - acc: 0.6988 - val_loss: 1.2958 - val_acc: 0.6371\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.0717 - acc: 0.7101 - val_loss: 1.0321 - val_acc: 0.7208\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 1.0367 - acc: 0.7234 - val_loss: 1.0059 - val_acc: 0.7302\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0179 - acc: 0.7250 - val_loss: 1.0449 - val_acc: 0.7129\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.0156 - acc: 0.7243 - val_loss: 0.9884 - val_acc: 0.7322\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9918 - acc: 0.7334 - val_loss: 1.0674 - val_acc: 0.6988\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9665 - acc: 0.7358 - val_loss: 0.9735 - val_acc: 0.7442\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9495 - acc: 0.7451 - val_loss: 0.9708 - val_acc: 0.7368\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9340 - acc: 0.7473 - val_loss: 0.9937 - val_acc: 0.7240\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9265 - acc: 0.7486 - val_loss: 0.9160 - val_acc: 0.7469\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.9192 - acc: 0.7505 - val_loss: 0.9189 - val_acc: 0.7513\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8841 - acc: 0.7623 - val_loss: 0.9103 - val_acc: 0.7521\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8702 - acc: 0.7661 - val_loss: 0.8798 - val_acc: 0.7611\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8631 - acc: 0.7670 - val_loss: 0.8819 - val_acc: 0.7585\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8615 - acc: 0.7660 - val_loss: 0.8492 - val_acc: 0.7708\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.8517 - acc: 0.7691 - val_loss: 0.8822 - val_acc: 0.7571\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.8387 - acc: 0.7722 - val_loss: 0.8457 - val_acc: 0.7693\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8259 - acc: 0.7764 - val_loss: 0.8369 - val_acc: 0.7733\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8219 - acc: 0.7768 - val_loss: 0.8668 - val_acc: 0.7677\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8143 - acc: 0.7793 - val_loss: 0.8370 - val_acc: 0.7763\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8097 - acc: 0.7787 - val_loss: 0.8353 - val_acc: 0.7707\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.8082 - acc: 0.7803 - val_loss: 0.8248 - val_acc: 0.7736\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7978 - acc: 0.7840 - val_loss: 0.8622 - val_acc: 0.7638\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7958 - acc: 0.7859 - val_loss: 0.9029 - val_acc: 0.7486\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7937 - acc: 0.7844 - val_loss: 0.8363 - val_acc: 0.7697\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7864 - acc: 0.7867 - val_loss: 0.8817 - val_acc: 0.7547\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7827 - acc: 0.7877 - val_loss: 0.8222 - val_acc: 0.7733\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7839 - acc: 0.7856 - val_loss: 0.8201 - val_acc: 0.7762\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7810 - acc: 0.7859 - val_loss: 0.7994 - val_acc: 0.7847\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7771 - acc: 0.7881 - val_loss: 0.8287 - val_acc: 0.7735\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7739 - acc: 0.7907 - val_loss: 0.8303 - val_acc: 0.7742\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7670 - acc: 0.7914 - val_loss: 0.8242 - val_acc: 0.7747\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7691 - acc: 0.7883 - val_loss: 0.8027 - val_acc: 0.7789\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7597 - acc: 0.7928 - val_loss: 0.8144 - val_acc: 0.7736\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7618 - acc: 0.7918 - val_loss: 0.8031 - val_acc: 0.7787\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7513 - acc: 0.7960 - val_loss: 0.8093 - val_acc: 0.7733\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7503 - acc: 0.7974 - val_loss: 0.7967 - val_acc: 0.7835\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7572 - acc: 0.7925 - val_loss: 0.8047 - val_acc: 0.7812\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7533 - acc: 0.7937 - val_loss: 0.7974 - val_acc: 0.7852\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7365 - acc: 0.7993 - val_loss: 0.7961 - val_acc: 0.7741\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7516 - acc: 0.7952 - val_loss: 0.7895 - val_acc: 0.7874\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7415 - acc: 0.7978 - val_loss: 0.8099 - val_acc: 0.7749\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7470 - acc: 0.7954 - val_loss: 0.7988 - val_acc: 0.7797\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7407 - acc: 0.7980 - val_loss: 0.7765 - val_acc: 0.7873\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7375 - acc: 0.7973 - val_loss: 0.7863 - val_acc: 0.7815\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7297 - acc: 0.8008 - val_loss: 0.8012 - val_acc: 0.7809\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7245 - acc: 0.8001 - val_loss: 0.7790 - val_acc: 0.7863\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7296 - acc: 0.8004 - val_loss: 0.7722 - val_acc: 0.7870\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7234 - acc: 0.8044 - val_loss: 0.8007 - val_acc: 0.7798\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7252 - acc: 0.8027 - val_loss: 0.8116 - val_acc: 0.7790\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7197 - acc: 0.8020 - val_loss: 0.8101 - val_acc: 0.7724\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7175 - acc: 0.8050 - val_loss: 0.7878 - val_acc: 0.7813\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7226 - acc: 0.8011 - val_loss: 0.7909 - val_acc: 0.7843\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.7150 - acc: 0.8068 - val_loss: 0.7937 - val_acc: 0.7756\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7172 - acc: 0.8020 - val_loss: 0.7776 - val_acc: 0.7817\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7092 - acc: 0.8060 - val_loss: 0.8044 - val_acc: 0.7773\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7076 - acc: 0.8070 - val_loss: 0.7675 - val_acc: 0.7851\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7072 - acc: 0.8056 - val_loss: 0.7961 - val_acc: 0.7801\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7074 - acc: 0.8063 - val_loss: 0.7630 - val_acc: 0.7890\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7010 - acc: 0.8085 - val_loss: 0.7662 - val_acc: 0.7899\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7113 - acc: 0.8062 - val_loss: 0.7862 - val_acc: 0.7853\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7006 - acc: 0.8084 - val_loss: 0.7657 - val_acc: 0.7915\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.6990 - acc: 0.8065 - val_loss: 0.7556 - val_acc: 0.7913\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7011 - acc: 0.8099 - val_loss: 0.7659 - val_acc: 0.7875\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6972 - acc: 0.8096 - val_loss: 0.7511 - val_acc: 0.7904\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.7021 - acc: 0.8092 - val_loss: 0.7704 - val_acc: 0.7861\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6959 - acc: 0.8092 - val_loss: 0.7751 - val_acc: 0.7881\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6928 - acc: 0.8107 - val_loss: 0.7806 - val_acc: 0.7816\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6955 - acc: 0.8095 - val_loss: 0.7834 - val_acc: 0.7835\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6925 - acc: 0.8099 - val_loss: 0.7550 - val_acc: 0.7926\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6926 - acc: 0.8110 - val_loss: 0.7622 - val_acc: 0.7903\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6845 - acc: 0.8143 - val_loss: 0.7647 - val_acc: 0.7901\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6844 - acc: 0.8131 - val_loss: 0.7566 - val_acc: 0.7870\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6811 - acc: 0.8121 - val_loss: 0.7869 - val_acc: 0.7808\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6874 - acc: 0.8114 - val_loss: 0.7623 - val_acc: 0.7903\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                              steps_per_epoch=x_train.shape[0] // 32,\n",
    "                              validation_data=datagen.flow(x_val, y_val, batch_size=8),\n",
    "                              validation_steps=x_val.shape[0] // 8,\n",
    "                              epochs = 100,\n",
    "                              callbacks=[early_stopping, checkpoint, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85f00c7668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"val\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"r\", label=\"train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"val\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 132us/step\n",
      "test score: 0.6452600821495056\n",
      "test accuracy: 0.8242\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('test score:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tip!\n",
    "\n",
    "[keras application](https://keras.io/applications/#mobilenet)의 mobilenet을 사용하면 매우 편리하게 imagenet으로 학습된 모델을 가져올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf.h5\n",
      "17227776/17225924 [==============================] - 14s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet\n",
    "\n",
    "model = mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact me\n",
    "케라스를 사랑하는 개발자 입니다.\n",
    "\n",
    "질문, 조언, contribtuion 등 소통은 언제나 환영합니다.\n",
    "\n",
    "Anthony Kim(김동현) : artit.anthony@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
